#!/bin/bash

#SBATCH --job-name=PDMP    # create a short name for your job
#SBATCH --nodes=1                # node count
#SBATCH --ntasks=1               # total number of tasks across all nodes
#SBATCH --cpus-per-task=12       # cpu-cores per task (>1 if multi-threaded tasks)
#SBATCH --partition=cpu_homogen          # Name of the partition
#### ### SBATCH --gres=gpu:1     # GPU nodes are only available in gpu partition
#SBATCH --time=48:00:00          # total run time limit (HH:MM:SS)
#SBATCH --mem=24G                # Total memory allocated
# ### ### SBATCH --hint=multithread       # we get physical cores not logical
#SBATCH --output=./log/%x_%j.out   # output file name
#SBATCH --array=5              # job array index

echo "### Running $SLURM_JOB_NAME with array task $SLURM_ARRAY_TASK_ID ###"

set -x
cd ${SLURM_SUBMIT_DIR}

module purge
module load cuda/11.4.0

source /home/$USER/.bashrc
conda activate diffusion

exp_number=0

epochs=300
folder="cleps/gmm_2"


datasets=('rose' 'olympic_rings' 'fractal_tree' 'checkerboard' 'gmm_grid' 'gmm_2')
# use fractal_tree
#transforms=(4 8 12 24)

# best models

#python ./run_pdmp.py --config 2d_data --job_id $SLURM_JOB_ID --name ${folder}_$exp_number --epochs $epochs --eval $epochs --reverse_steps 100 --noising_process pdmp --sampler BPS --refresh_rate 1.0 --ml_loss --depth 8 --width 256 --transforms 8  --time_horizon 3 --dataset ${datasets[${SLURM_ARRAY_TASK_ID}]}
python ./run_pdmp.py --config 2d_data --job_id $SLURM_JOB_ID --name ${folder}_$exp_number --epochs $epochs --eval $epochs --reverse_steps 100 --noising_process pdmp --sampler HMC --refresh_rate 1.0 --ml_loss --depth 8 --width 256 --transforms 8  --time_horizon 3 --dataset ${datasets[${SLURM_ARRAY_TASK_ID}]}
#python ./run_pdmp.py --config 2d_data --job_id $SLURM_JOB_ID --name ${folder}_$exp_number --epochs $epochs --eval $epochs --reverse_steps 100 --noising_process pdmp --sampler ZigZag --refresh_rate 1.0 --hyvarinen_loss --blocks 24 --units 256 --time_horizon 3 --dataset ${datasets[${SLURM_ARRAY_TASK_ID}]} 
#python ./run_pdmp.py --config 2d_data --job_id $SLURM_JOB_ID --name ${folder}_$exp_number --epochs $epochs --eval $epochs --reverse_steps 100 --noising_process diffusion --blocks 24 --units 256  --time_horizon 3 --dataset ${datasets[${SLURM_ARRAY_TASK_ID}]}

# normal nf
#python ./run_pdmp.py --config 2d_data --job_id $SLURM_JOB_ID --name ${folder}_$exp_number --epochs $epochs --eval $epochs --reverse_steps 1 --noising_process nf --dataset ${datasets[${SLURM_ARRAY_TASK_ID}]}


#python ./run_pdmp.py --config 2d_data  --name tmp --epochs 10 --eval 10 --reverse_steps 100 --noising_process pdmp --sampler HMC --refresh_rate 1.0 --ml_loss --depth 3 --width 256 --transforms 3  --time_horizon 3 --dataset gmm_2


# test
#python ./run_pdmp.py --config 2d_data --job_id $SLURM_JOB_ID --name tmp --epochs 1000 --eval 1000 --reverse_steps 100 --noising_process pdmp --sampler ZigZag --refresh_rate 1.0 --hyvarinen_loss --blocks 24 --units 256 --time_horizon 3 --dataset gmm_2


# old
#python ./run_pdmp.py --config 2d_data --name ${folder}_$exp_number --epochs $epochs --eval 100 --check $epochs --reverse_steps 100  --dataset fractal_tree  --noising_process pdmp --sampler BPS --refresh_rate 1.0 --ml_loss --depth 3 --width 256 --transforms 8
#python ./run_pdmp.py --config 2d_data --name ${folder}_$exp_number --epochs $epochs --eval 100 --check $epochs --reverse_steps 100  --dataset fractal_tree  --noising_process pdmp --sampler HMC --refresh_rate 1.0 --ml_loss --depth 3 --width 256 --transforms 8
#python ./run_pdmp.py --config 2d_data --name ${folder}_$exp_number --epochs $epochs --eval 100 --check $epochs --reverse_steps 100  --dataset fractal_tree  --noising_process pdmp --sampler HMC --refresh_rate 1.0 --hyvarinen_loss --blocks 64 --units 128
#python ./run_pdmp.py --config 2d_data --name ${folder}_$exp_number --epochs $epochs --eval 100 --check $epochs --reverse_steps 100  --dataset fractal_tree  --noising_process diffusion --blocks 64 --units 128 


# now evaluate last models with varying reverse_steps
#reverse_steps=(2 5 10 25 50 100 250)
#for i in $(seq 0 $(( ${#reverse_steps[@]} - 1)) ) ; do
    #python ./eval_pdmp.py --config 2d_data --name ${folder}_$exp_number --epochs $epochs --eval $epochs --reverse_steps ${reverse_steps[${i}]} --noising_process pdmp --sampler BPS --refresh_rate 1.0 --ml_loss --depth 8 --width 256 --transforms 8  --time_horizon 3 --dataset ${datasets[${SLURM_ARRAY_TASK_ID}]}
    #python ./eval_pdmp.py --config 2d_data --name ${folder}_$exp_number --epochs $epochs --eval $epochs --reverse_steps ${reverse_steps[${i}]} --noising_process pdmp --sampler HMC --refresh_rate 1.0 --ml_loss --depth 8 --width 256 --transforms 8  --time_horizon 3 --dataset ${datasets[${SLURM_ARRAY_TASK_ID}]}
    #python ./eval_pdmp.py --config 2d_data --name ${folder}_$exp_number --epochs $epochs --eval $epochs --reverse_steps ${reverse_steps[${i}]} --noising_process pdmp --sampler ZigZag --refresh_rate 1.0 --hyvarinen_loss --blocks 24 --units 256  --time_horizon 3 --dataset ${datasets[${SLURM_ARRAY_TASK_ID}]}
#    python ./eval_pdmp.py --config 2d_data --name ${folder}_$exp_number --epochs $epochs --eval $epochs --reverse_steps ${reverse_steps[${i}]} --noising_process diffusion --blocks 24 --units 256 --dataset ${datasets[${SLURM_ARRAY_TASK_ID}]}
#done


#python ./eval_pdmp.py --config 2d_data --name cleps/paper_toy_data_0 --epochs 1000 --eval 1000 --reverse_steps 5 --noising_process pdmp --sampler ZigZag --refresh_rate 1.0 --hyvarinen_loss --blocks 24 --units 256 --transforms 8  --time_horizon 3 --dataset rose
