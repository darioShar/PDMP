#!/bin/bash

#SBATCH --job-name=PDMP    # create a short name for your job
#SBATCH --nodes=1                # node count
#SBATCH --ntasks=1               # total number of tasks across all nodes
#SBATCH --cpus-per-task=12       # cpu-cores per task (>1 if multi-threaded tasks)
#SBATCH --partition=cpu_homogen          # Name of the partition
## ## #SBATCH --gres=gpu:1     # GPU nodes are only available in gpu partition
#SBATCH --time=48:00:00          # total run time limit (HH:MM:SS)
#SBATCH --mem=12G                # Total memory allocated
# ### ### SBATCH --hint=multithread       # we get physical cores not logical
#SBATCH --output=./log/%x_%j.out   # output file name
#SBATCH --array=0-9              # job array index

exp_number=$SLURM_ARRAY_TASK_ID

echo "### Running $SLURM_JOB_NAME with array task $SLURM_ARRAY_TASK_ID ###"

set -x
cd ${SLURM_SUBMIT_DIR}

module purge
module load cuda/11.4.0

source /home/$USER/.bashrc
conda activate diffusion

# Lp=('1.0' '1.5' '2.0')

# we need to run BPS, HMC, ZigZag, diffusion on 2D data.
# I want to compare end results
# and I want to see how this scales with diffusion steps. We'll do that with eval_pdmp.py at the end. Let's go with 100 diffusion steps for everybody at first, with a simple 4-gmm

# first train the models

epochs=300


# we must use the same add_losses for run and eval.

echo "Submitting experiment ${exp_number}, pdmp with sampler=BPS"
python ./run_pdmp.py --config 2d_data --name experiment_$exp_number --epochs $epochs --eval 50 --reverse_steps 100 --noising_process pdmp --sampler BPS --refresh_rate 1.0 --ml_loss --logistic_loss
echo "Submitting experiment ${exp_number}, pdmp with sampler=HMC"
python ./run_pdmp.py --config 2d_data --name experiment_$exp_number --epochs $epochs --eval 50 --reverse_steps 100 --noising_process pdmp --sampler HMC --refresh_rate 1.0 --ml_loss --logistic_loss
echo "Submitting experiment ${exp_number}, pdmp with sampler=ZigZag"
python ./run_pdmp.py --config 2d_data --name experiment_$exp_number --epochs $epochs --eval 50 --reverse_steps 100 --noising_process pdmp --sampler ZigZag --refresh_rate 1.0 --hyvarinen_loss
echo "Submitting experiment ${exp_number}, diffusion"
python ./run_pdmp.py --config 2d_data --name experiment_$exp_number --epochs $epochs --eval 50 --reverse_steps 100 --noising_process diffusion


# now evaluate last models with varying reverse_steps
reverse_steps=(1 2 3 5 10 20 30 50 100 200)
for i in $(seq 0 $(( ${#reverse_steps[@]} - 1)) ) ; do
    echo "Evaluating experiment ${exp_number} with reverse_steps=${reverse_steps[${i}]}"
    # pdmp
    python ./eval_pdmp.py --config 2d_data --name cleps/experiment_$exp_number --epochs $epochs --eval $epochs --reverse_steps ${reverse_steps[${i}]} --noising_process pdmp --sampler BPS --refresh_rate 1.0 --ml_loss --logistic_loss
    python ./eval_pdmp.py --config 2d_data --name cleps/experiment_$exp_number --epochs $epochs --eval $epochs --reverse_steps ${reverse_steps[${i}]} --noising_process pdmp --sampler HMC --refresh_rate 1.0 --ml_loss --logistic_loss
    python ./eval_pdmp.py --config 2d_data --name cleps/experiment_$exp_number --epochs $epochs --eval $epochs --reverse_steps ${reverse_steps[${i}]} --noising_process pdmp --sampler ZigZag --refresh_rate 1.0 --hyvarinen_loss
    # diffusion
    python ./eval_pdmp.py --config 2d_data --name cleps/experiment_$exp_number --epochs $epochs --eval $epochs --reverse_steps ${reverse_steps[${i}]} --noising_process diffusion 
done
